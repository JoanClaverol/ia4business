TD = R_new[current_state, next_state] + gamma*Q[next_state, np.argmax(Q[next_state,])] - Q[current_state, next_state]
Q[current_state, next_state] += alpha*TD
return Q
# vamos a crear una funcion donde un modelo nos devolvera la ruta más óptima en
# base a un punto de inicio A a un punto de inicio B
# los valores entrados en la funcion no seran numericos, sino caracteres
def best_route(starting_location, ending_location, middle_locations=None):#, middle_location):
# Create Q values
Q = Q_values(starting_location, ending_location)
# lista para almacenar la ruta
route = [starting_location]
next_location = starting_location
while next_location != ending_location and middle_locations:
# if not middle_locations:
next_location = starting_location
# else:
#   Q = Q_values(starting_location, middle_location[0])
#   middle_locations = middle_locations[1:]
#   print("Something to do")
try:
starting_state = location_to_state[next_location]
next_state = np.argmax(Q[starting_state, ])
next_location = state_to_location[next_state]
route.append(next_location)
except:
middle_locations = None
print("Nop, didn't work")
# else:
#   while not middle_locations:
#     # define the temporary end location (middle location)
#     temp_end_loc = middle_locations[0]
#     middle_locations = middle_locations[1:] # remove location already added
#     temp_start_loc = route[-1] #
#     # Get the Q values
#     Q = Q_values(starting_location=temp_start_loc, ending_location=temp_end_loc)
#     next_location = middle_locations.pop([0])
#     next_location = temp_start_loc
#     while next_location != temp_end_loc:
#       starting_state = location_to_state[next_location]
#       next_state = np.argmax(Q[starting_state, ])
#       next_location = state_to_location[next_state]
#       route.append(next_location)
return route
print("La ruta elegida es:")
print(best_route(starting_location="E", ending_location="G"))
ending_location
starting_location
Q = Q_values(starting_location, ending_location)
route = [starting_location]
next_location = starting_location
location_to_state[next_location]
def best_route(starting_location, ending_location, middle_locations=None):#, middle_location):
# Create Q values
Q = Q_values(starting_location, ending_location)
# lista para almacenar la ruta
route = [starting_location]
next_location = starting_location
while next_location != ending_location and middle_locations:
# if not middle_locations:
# next_location = starting_location
# else:
#   Q = Q_values(starting_location, middle_location[0])
#   middle_locations = middle_locations[1:]
#   print("Something to do")
try:
starting_state = location_to_state[next_location]
next_state = np.argmax(Q[starting_state, ])
next_location = state_to_location[next_state]
route.append(next_location)
except:
middle_locations = None
print("Nop, didn't work")
# else:
#   while not middle_locations:
#     # define the temporary end location (middle location)
#     temp_end_loc = middle_locations[0]
#     middle_locations = middle_locations[1:] # remove location already added
#     temp_start_loc = route[-1] #
#     # Get the Q values
#     Q = Q_values(starting_location=temp_start_loc, ending_location=temp_end_loc)
#     next_location = middle_locations.pop([0])
#     next_location = temp_start_loc
#     while next_location != temp_end_loc:
#       starting_state = location_to_state[next_location]
#       next_state = np.argmax(Q[starting_state, ])
#       next_location = state_to_location[next_state]
#       route.append(next_location)
return route
print("La ruta elegida es:")
print(best_route(starting_location="E", ending_location="G"))
next_location
ending_location
middle_locations
middle_locations=None
middle_locations
while next_location != ending_location and middle_locations:
# if not middle_locations:
# next_location = starting_location
# else:
#   Q = Q_values(starting_location, middle_location[0])
#   middle_locations = middle_locations[1:]
#   print("Something to do")
try:
starting_state = location_to_state[next_location]
next_state = np.argmax(Q[starting_state, ])
next_location = state_to_location[next_state]
route.append(next_location)
except:
middle_locations = None
print("Nop, didn't work")
route
reticulate::source_python('~/Documents/LEARN/ia4business/notes/optimizacion_procesos_industriales_v3.py')
reticulate::source_python('~/Documents/LEARN/ia4business/notes/optimizacion_procesos_industriales_v3.py')
reticulate::repl_python()
reticulate::source_python('~/Documents/LEARN/ia4business/notes/optimizacion_procesos_industriales_v3.py')
reticulate::repl_python()
reticulate::source_python('~/Documents/LEARN/ia4business/notes/optimizacion_procesos_industriales_v4.py')
reticulate::repl_python()
reticulate::source_python('~/Documents/LEARN/ia4business/Part 1 - Optimizing Business Processes/qlearning.py')
reticulate::source_python('~/Documents/LEARN/ia4business/notes/personal_projects/snake.py')
reticulate::repl_python()
reticulate::source_python('~/Documents/LEARN/ia4business/notes/optimizacion_procesos_industriales_v3.py')
reticulate::repl_python()
reticulate::source_python('~/Documents/LEARN/ia4business/notes/optimizacion_procesos_industriales_v3.py')
reticulate::source_python('~/Documents/LEARN/ia4business/notes/optimizacion_procesos_industriales_v3.py')
best_route('E',"B")
best_route('E',"B",['D'])
best_route('E',"B",'D')
best_route('E',"B",c('D','L'))
library(lubridate)
source('~/.active-rstudio-document', echo=TRUE)
df <- read_rds('/Users/joanC/Downloads/data_ready.rds')
df
df %>%
ggplot(aes(date, Kitchen_avg)) +
geom_line()
df %>%
tidyr::pivot_longer(
cols = c("Kitchen_avg","Laundry_avg","W.A_HeatCold_avg","UnkownEnergy_avg"),
names_to = "submeters", values_to = "values"
)
df %>%
tidyr::pivot_longer(
cols = c("Kitchen_avg","Laundry_avg","W.A_HeatCold_avg","UnkownEnergy_avg"),
names_to = "submeters", values_to = "values"
) %>%
ggplot(aes(x=date, y=values, col=submeters)) +
geom_line()
df %>%
tidyr::pivot_longer(
cols = c("Kitchen_avg","Laundry_avg","W.A_HeatCold_avg","UnkownEnergy_avg"),
names_to = "submeters", values_to = "values"
) %>%
ggplot(aes(x=date, y=values, col=submeters, group=submeters)) +
geom_line()
df %>%
tidyr::pivot_longer(
cols = c("Kitchen_avg","Laundry_avg","W.A_HeatCold_avg","UnkownEnergy_avg"),
names_to = "submeters", values_to = "values"
) %>%
ggplot(aes(x=date, y=values, col=submeters)) +
geom_line(alpha=0.3)
df %>%
tidyr::pivot_longer(
cols = c("Kitchen_avg","Laundry_avg","W.A_HeatCold_avg","UnkownEnergy_avg"),
names_to = "submeters", values_to = "values"
) %>%
ggplot(aes(x=date, y=values, col=submeters)) +
geom_line(alpha=0.7)
reticulate::repl_python()
reticulate::py_install('bs4')
reticulate::py_install('urllib')
reticulate::repl_python()
reticulate::py_install('requests')
reticulate::repl_python()
# Thomas code: review
# libraries ---------------------------------------------------------------
if(require("pacman")=="FALSE"){
install.packages("pacman")
}
pacman::p_load(tidyverse, lubridate, forecast, shiny, shinydashboard, dplyr)# load
# load data ---------------------------------------------------------------
# library(readr) # this is not necessary, you already loaded the libraries
path <- c('/Users/joanC/Downloads/')
Data <- read_delim(paste0(path, "household_power_consumption.txt"),
";", col_types = cols(Date = col_date(format = "%d/%m/%Y")))
# data wrangling ----------------------------------------------------------
Data <- Data %>%
unite(Date, Time, col = "Datetime", sep = " ") %>%
mutate(date_time = parse_datetime(Datetime, locale = locale(tz = "UTC")))
# prepare daily data
dayData <- Data %>%
group_by(year=year(Datetime),
month=month(Datetime),
day=day(Datetime)) %>%
summarise(day_energy_avg = mean(Global_active_power, na.rm = TRUE)) %>%
ungroup()
# train model -------------------------------------------------------------
ts_dayData <- ts(dayData$day_energy_avg,
frequency = 365.25,
start = c(2007, 1))
linearmodel <- tslm(ts_dayData ~ trend + season)
# write_rds(linearmodel,"C:/Users/Thomas S/Documents/Ubiqum/3. IoT Analytics/2. Visualize and Analyze Energy Data/Shiny/Shiny/Shiny2/Data 2/lm_Shiny.rds")
# linearmodel <- read_rds("C:/Users/Thomas S/Documents/Ubiqum/3. IoT Analytics/2. Visualize and Analyze Energy Data/Shiny/Shiny/Shiny2/Data 2/lm_Shiny.rds")
dim(Data)
SubData <- Data %>%
group_by(year=year(Datetime),
month=month(Datetime),
day=day(Datetime),
hour=hour(Datetime)) %>%
summarise(sub1_avg = mean(Sub_metering_1, na.rm = TRUE),
sub2_avg = mean(Sub_metering_2, na.rm = TRUE),
sub3_avg = mean(Sub_metering_3, na.rm = TRUE),) %>%
ungroup()
SubData
#merge the  year,month,day,hour columns to one column so that comparison(later can be made)
SubData <- SubData %>%
unite(c(day, month, year), col = "dmY", sep = " ")
SubData
#save in date format
SubData$dmY <-as.POSIXct(SubData$dmY, format ="%d%m%Y", tz="UTC")
SubData
#merge the  year,month,day,hour columns to one column so that comparison(later can be made)
SubData <- SubData %>%
unite(c(day, month, year,hour), col = "dmY", sep = " ") %>%
mutate(dmy_h("dmY"))
rlang::last_error()
#save in date format
SubData$dmY <-as.POSIXct(SubData$dmY, format ="%d%m%Y", tz="UTC")
Sub_Data_Pivot <- SubData %>%
tidyr::pivot_longer(
cols = c("sub1_avg","sub2_avg","sub3_avg"),
names_to = "submeters", values_to = "values"
)
Sub_Data_Pivot
Acitve_and_Reactive_Data <- Data %>%
group_by(year=year(Datetime),
month=month(Datetime),
day=day(Datetime),
hour=hour(Datetime)) %>%
summarise(Global_APower = mean(Global_active_power, na.rm = TRUE),
Global_RPower = mean(Global_reactive_power, na.rm = TRUE)) %>%
ungroup()
#merge the  year,month,day,hour columns to one column so that comparison(later can be made)
Acitve_and_Reactive_Data <- Acitve_and_Reactive_Data %>%
unite(c(day, month, year), col = "dmY", sep = " ")
#save in date format
Acitve_and_Reactive_Data$dmY <-as.POSIXct(Acitve_and_Reactive_Data$dmY,
format ="%d%m%Y", tz="UTC")
Acitve_and_Reactive_Pivot <- Acitve_and_Reactive_Data %>%
tidyr::pivot_longer(
cols = c("Global_APower","Global_RPower"),
names_to = "global_power", values_to = "values"
)
Voltage_Data <- Data %>%
group_by(year=year(Datetime),
month=month(Datetime),
day=day(Datetime),
hour=hour(Datetime)) %>%
summarise(voltage = mean(Voltage, na.rm = TRUE)) %>%
ungroup()
#merge the  year,month,day,hour columns to one column so that comparison(later can be made)
Voltage_Data <- Voltage_Data %>%
unite(c(day, month, year), col = "dmY", sep = " ")
#save in date format
Voltage_Data$dmY <-as.POSIXct(Voltage_Data$dmY,
format ="%d%m%Y", tz="UTC")
Voltage_Pivot <- Voltage_Data %>%
tidyr::pivot_longer(
cols = c("voltage"),
names_to = "voltage", values_to = "values"
)
Global_Intensity_Data <- Data %>%
group_by(year=year(Datetime),
month=month(Datetime),
day=day(Datetime),
hour=hour(Datetime)) %>%
summarise(intensity = mean(Global_intensity, na.rm = TRUE)) %>%
ungroup()
#merge the  year,month,day,hour columns to one column so that comparison(later can be made)
Global_Intensity_Data <- Global_Intensity_Data %>%
unite(c(day, month, year), col = "dmY", sep = " ")
#save in date format
Global_Intensity_Data$dmY <-as.POSIXct(Global_Intensity_Data$dmY,
format ="%d%m%Y", tz="UTC")
Global_Intensity_Pivot <- Global_Intensity_Data %>%
tidyr::pivot_longer(
cols = c("intensity"),
names_to = "intensity", values_to = "values"
)
# ui ----------------------------------------------------------------------
ui <- dashboardPage(
dashboardHeader(),
dashboardSidebar(
sliderInput(
inputId = "slider_days_predicted",
label = "Choose the number of days you would like to have predicted",
min = 1, max = 365, value = 25
),
sliderInput(
inputId = "choose_day",
label = "Choose Day",
min = as.Date("16-12-2006","%d-%m-%Y"),
max = as.Date("26-11-2010","%d-%m-%Y"),
value = as.Date("16-12-2006","%d-%m-%Y")
)
),
dashboardBody(
box(plotOutput(outputId = "plot1")),
box(plotOutput(outputId = "plot2")),
box(plotOutput(outputId = "plot3")),
box(plotOutput(outputId = "plot4")),
box(plotOutput(outputId = "plot5"))
)
)
# server ------------------------------------------------------------------
server <- function(input, output) {
output$plot1 <- renderPlot({
forecast_day_data <- forecast(linearmodel,
h=input$slider_days_predicted)
autoplot(forecast_day_data, xlab="Time")
})
output$plot2 <- renderPlot({
Acitve_and_Reactive_Pivot %>%
filter(dmY == input$choose_day) %>%
ggplot(aes(x=hour,y=values, col = global_power))+
geom_step()
})
output$plot3 <- renderPlot({
Voltage_Pivot %>%
filter(dmY == input$choose_day) %>%
ggplot(aes(x=hour,y=values, col = voltage))+
geom_step()
})
output$plot4 <- renderPlot({
Sub_Data_Pivot %>%
filter(dmY == input$choose_day) %>%
ggplot(aes(x=hour, y=values, col = submeters))+
geom_step()
})
output$plot5 <- renderPlot({
Global_Intensity_Pivot %>%
filter(dmY == input$choose_day) %>%
ggplot(aes(x=hour, y=values, col = intensity))+
geom_step()
})
}
shinyApp(ui, server)
forecast(linearmodel, h=10)
forecast_day_data <- forecast(linearmodel, h=10)
autoplot(forecast_day_data, xlab="Time")
autoplot(forecast_day_data)
forecast_day_data
forecast_day_data <- forecast(linearmodel, h=30)
linearmodel
dayData
# prepare daily data
dayData <- Data %>%
group_by(year=year(Datetime),
month=month(Datetime),
day=day(Datetime)) %>%
summarise(day_energy_avg = mean(Global_active_power, na.rm = TRUE)) %>%
ungroup() %>%
filter(year != 2006)
# prepare daily data
dayData <- Data %>%
filter(year != 2006) %>% # specify completed years
group_by(year=year(Datetime),
month=month(Datetime),
day=day(Datetime)) %>%
summarise(day_energy_avg = mean(Global_active_power, na.rm = TRUE)) %>%
ungroup()
# prepare daily data
dayData <- Data %>%
filter(year != 2006) %>% # specify completed years
group_by(year=year(Datetime),
month=month(Datetime),
day=day(Datetime)) %>%
summarise(day_energy_avg = mean(Global_active_power, na.rm = TRUE)) %>%
ungroup()
names(Data)
# prepare daily data
dayData <- Data %>%
filter(year(date_time) != 2006) %>% # specify completed years
group_by(year=year(Datetime),
month=month(Datetime),
day=day(Datetime)) %>%
summarise(day_energy_avg = mean(Global_active_power, na.rm = TRUE)) %>%
ungroup()
# train model -------------------------------------------------------------
ts_dayData <- ts(dayData$day_energy_avg,
frequency = 365.25,
start = c(2007, 1))
linearmodel <- tslm(ts_dayData ~ trend + season)
autoplot(linearmodel)
forecast(linearmodel)
autoplot(forecast(linearmodel))
# prepare daily data
dayData <- Data %>%
filter(year(date_time) != 2006) %>% # specify completed years
group_by(year=year(Datetime),
month=month(Datetime),
day=day(Datetime)) %>%
summarise(day_energy_avg = mean(Global_active_power, na.rm = TRUE)) %>%
ungroup() %>%
drop_na()
# train model -------------------------------------------------------------
ts_dayData <- ts(dayData$day_energy_avg,
frequency = 365.25,
start = c(2007, 1))
linearmodel <- tslm(ts_dayData ~ trend + season)
autoplot(forecast(linearmodel))
# libraries ---------------------------------------------------------------
if(require("pacman")=="FALSE"){
install.packages("pacman")
}
pacman::p_load(tidyverse, lubridate, forecast, shiny, shinydashboard, dplyr)# load
# load data ---------------------------------------------------------------
# library(readr) # this is not necessary, you already loaded the libraries
path <- c('/Users/joanC/Downloads/')
Data <- read_delim(paste0(path, "household_power_consumption.txt"),
";", col_types = cols(Date = col_date(format = "%d/%m/%Y")))
summary(data)
summary(Data)
# data wrangling ----------------------------------------------------------
Data <- Data %>%
unite(Date, Time, col = "Datetime", sep = " ") %>%
mutate(date_time = parse_datetime(Datetime, locale = locale(tz = "UTC")))
summary(data)
summary(Data)
# prepare daily data
dayData <- Data %>%
filter(year(date_time) != 2006) %>% # specify completed years
group_by(year=year(Datetime),
month=month(Datetime),
day=day(Datetime)) %>%
summarise(day_energy_avg = mean(Global_active_power, na.rm = TRUE)) %>%
ungroup() %>%
drop_na()
summary(dayData)
# train model -------------------------------------------------------------
ts_dayData <- ts(dayData$day_energy_avg,
frequency = 365.25,
start = c(2007, 1))
linearmodel <- tslm(ts_dayData ~ trend + season)
autoplot(forecast(linearmodel, h=30))
glimpse(Data)
# prepare daily data
dayData <- Data %>%
filter(year(date_time) != 2006) %>% # specify completed years
group_by(year=year(date_time),
month=month(date_time),
day=day(date_time)) %>%
summarise(day_energy_avg = mean(Global_active_power, na.rm = TRUE)) %>%
ungroup() %>%
drop_na()
# train model -------------------------------------------------------------
ts_dayData <- ts(dayData$day_energy_avg,
frequency = 365.25,
start = c(2007, 1))
linearmodel <- tslm(ts_dayData ~ trend + season)
autoplot(forecast(linearmodel, h=30))
dayData
autoplot(ts_dayData)
reticulate::repl_python()
knitr::opts_chunk$set(echo = TRUE)
iris
iris
library(tidyverse)
library(reticulate)
df <- iris %>% as_tibble()
df
py_install('matplotlib')
py$py_df
new_df <- py$py_df
new_df %>%
ggplot(aes(Sepal.Width, Petal.Length)) +
geom_point()
reticulate::repl_python()
reticulate::py_install("TensorFlow")
reticulate::py_install("keras")
install.packages(c("googledrive", "pillar", "rlang", "ROCR", "zoo"))
reticulate::repl_python()
library(reticulate)
reticulate::source_python("temp.py")
reticulate::repl_python()
library(reticulate)
reticulate::source_python("temp.py")
hi
reticulate::repl_python()
write.csv(iris, "iris.csv")
reticulate::repl_python()
reticulate::source_python("temp.py")
data
reticulate::source_python("temp.py")
dictionary
dictionary[test]
dictionary["test"]
dictionary[["test"]]
install.packages("VIM")
print(2)
reticulate::py_install("keras")
print()
2
reticulate::source_python('~/Documents/LEARN/ia4business/Part 2 - Minimizing Costs/notas/environment.py')
reticulate::source_python('~/Documents/LEARN/ia4business/Part 2 - Minimizing Costs/notas/brain.py')
reticulate::source_python('~/Documents/LEARN/ia4business/Part 2 - Minimizing Costs/notas/dqn.py')
reticulate::source_python('~/Documents/LEARN/ia4business/Part 2 - Minimizing Costs/notas/training.py')
reticulate::source_python('~/Documents/LEARN/ia4business/Part 2 - Minimizing Costs/notas/testing.py')
reticulate::repl_python()
install.packages("dqshiny")
reticulate::repl_python()
